pd.Series(data,index=[])
ser.to_dict()
ser.tolist()
ser.to_json()
ser.to_frame()

pd.DataFrame(data,index=[],columns=[])

df['name']    df.name   df.age   series对象
df[['name','age']]    dataframe对象 这样的对象修改会影响原来的数据，可以使用  df.name.copy()
df.columns  取
df[df.columns[1:3]] 
df['year'] = datetime.datetime.now().year - df.age
df.drop('year', axis=1)
df.drop(df.columns[1::2], axis=1)
df.loc[1]   series对象
df.loc[[1,3]]   dataframe对象
df.loc[df.index[-2:]]
df.loc[df.index[-2:], ['name', 'age']]
df[1:3]
df[-2:]  直接df[2]报错，因为没有‘2’这一列

df.loc[df.shape[0]] = {'name':'','age':'','height':'','year':''}
df.drop(2)   删除行不用指定axis
df2.index = range(df2.shape[0])
df2.iloc[2]
df2.iat[1,1]  横纵都是隐藏的索引
df[df['height'] >= 1.65]
df[(df['height'] >= 1.65) & (df['age'] <=20)]
df.query('height>=1.65 and age <=20')
age=20
df.query('age == @age')
df[df['age'].isin([18,19])]
df.T 

pd.read_table('my/01.txt',sep=':',names=['','','',''])
pd.read_csv('my/04.csv')
pd.read_excel('')
tables = pd.read_html('my/05.html',header=0)
tables[0]  tables[1]
tables = pd.read_html('my/05.html',header=0,attrs={'class':'mydata'})
tables[0]
conn = pymysql.connect(host='', user='',passwd='',port='',db='',charset='utf8')
sql = 'select * from tablename'
data = pd.read_sql(sql, conn)
conn.close()

ser.sort_index(ascending=False)
ser.sort_values()   None值排序始终在最后
df.sort_index()
df.sort_index(axis=1)
df.sort_values(by='c')   df.sort_values(by=['a','c'])

df.rank()   得到的是排名情况，相当于索引
df.rank(method='frist')  #默认 average ，还有min，max

df.merge(df1,df2,on='stu_no',how='left')   how默认inner，还有right，left，outer    合并
pd.concat([df1,df2],axis=1)  拼接

df.head()    df.tail()
df.info()   df.describe()  空值将被跳过
df.count()   df.mean()  df.sum(axis=1) 
df.a.sum()    df.cumsum()  累加求和得到datafram
df.std()  df.var()  df.max()   df.min()
df.quantile(0.75)  df.quantile(0.25)

grouped = df.groupby('类别')
grouped[['数量','金额']].sum()
grouped[['单价']].max()
g = df.groupby(['类别','单价'])

df.pivot_table(index=['类别','名称'],values=['数量','金额'],aggfunc=np.sum)  # 默认是np.mean 平均

time模块
time.time()  浮点数
time.localtime()
time.strftime('%Y-%m-%d %H:%M:%S',time.time())
time.strptime('2018-02-25','%Y-%m-%d %H:%M:%S')

datetime 模块
now=datetime.now()
now.year  now.month
now.strftime('%Y-%m-%d %H:%M:%S')
now.timestamp() 转化成浮点数
datetime(2018,05,30)
datetime.fromtimestamp(time.time())

delta = datetime.now() - datetime(2018,5,28)
delta.days   delta.seconds   delta.hours

pd.date_range('2018-05-01','2018-05-11',freq=''D)   freq默认是D天，W周，M月，Q季度，A年，H小时，T分，S秒
pd.date_range('2018-05-01',freq='Q',periods=10) 指定周期
df[(df.time >= '2018-06-01 08:00:00') & (df.time <= '2018-06-10 08:00:00')]
df2 = df.set_index('time')
s = df.to_datetime(df.time)
df.index = s
时间序列切片好用
df['2018-06-01 08:00:00':'2018-06-01 08:00:00']
df['2018-06-01'] 直接取出这一天的数据
df.groupby(df.index.date).mean()  通过日期分组
df.groupby(df.index.week).mean()
df.groupby(df.index.hour).mean()

df2 = df.resample('90S').mean()  重新采样 90s间隔
df2 = df.resample('5T').max()

plt.rc('font', **{'family':'Microsoft YaHei, SimHei'})
data['工资'].plot()
plt.show()

data['工资'].plot(kind='bar')
plt.show()

data[['工资']].boxplot()
plt.show()

data[['工资']].hist()
plt.show()

data.plot(kind='barh', stacked=True)
plt.show()

探索性分析 数据质量分析
缺失值 
df.innull().sum()  df.notnull().sum() 
df['lang'] == '' 空值
异常值 
df.describe()  df[['salary']].boxplot()  箱线图找异常值
重复值 df.duplicated().sum() 
df.duplicated(subset=['lang']).sum() 
一致性
df.lang.unique()

数据特征分析
分布分析
np.max

对比分析
周期性分析
相关性分析
df.corr()  接近1和-1表示有相关，接近0没关系
install seaborn as sns
sns.heatmap(df.corr(), cmap=sns.color_palette('Blues'))
mask = np.zeros_like(df.corr(), dtype=np.bool)
ind = np.triu_indices_from(mask)

数据清理
df.dropna(how='all')
df.dropna(subset=['age'])
df.fillna(0)   df.fillna({'age':18, 'score':'d'})
df.fillna(method='ffill') 按前面的数据填充
df.fillna(method='bfill')   按后面的数据填充
df.fillna({'age':df.age.mean()})
df.fillna({'age':df.age.median()})
df.interpolate()  插值，默认线性插值
df.fillna({'score':'missing'}, limit=1)  limit只插值一次
df.drop_duplicates()
df.drop_duplicates(['age','score'])